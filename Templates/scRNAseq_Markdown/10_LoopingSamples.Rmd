---
title: "Looping over samples"
description: |
  Take all the fancy for loops and apply functions and put templates in one place
author: "Daniel Brown"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float:
      smooth_scroll: true
    theme: readable
    highlight: tango 
    df_print: paged
    code_folding: hide
editor_options: 
  chunk_output_type: console
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=8, fig.asp=0.618, 
                      fig.path='/Figures/NNxx/DataImport/',
                      warning=FALSE, message=FALSE)
```

```{r setup, include=FALSE}
library(here)
library(tidyverse)
library(scater)
library(scran)
library(BiocSingular)
library(batchelor)
```

# Make single-cell experiment object

This is a large dataset and so operating on the data will take longer than in previous examples.
* Counts matrix for each SCE is stored on disk in an HDF5 file

```{r}
library(TENxPBMCData)

all.sce <- list(
  pbmc3k=TENxPBMCData("pbmc3k"),
  pbmc4k=TENxPBMCData("pbmc4k"))
```

# Quality control

```{r}
stats <- high.mito <- list()

for (n in names(all.sce)) {
  current <- all.sce[[n]]
  is.mito <- grep("MT", rowData(current)$Symbol_TENx)
  stats[[n]] <- perCellQCMetrics(current, 
    subsets=list(Mito=is.mito))
  high.mito[[n]] <- isOutlier(stats[[n]]$subsets_Mito_percent,
    type="higher")
  all.sce[[n]] <- current[,!high.mito[[n]]]
}
```

# Normalization
```{r}
all.sce <- lapply(all.sce, logNormCounts)
```

# Variance-modelling
```{r}
all.dec <- lapply(all.sce, modelGeneVar)
all.hvgs <- lapply(all.dec, getTopHVGs, prop=0.1)
```

# Dimensionality-reduction
## PCA
```{r}
set.seed(10000)
all.sce <- mapply(FUN=runPCA, x=all.sce,
  subset_row=all.hvgs,
  MoreArgs=list(ncomponents=25, BSPARAM=RandomParam()), 
  SIMPLIFY=FALSE)
```

## t-SNE

```{r}
set.seed(100000)
all.sce <- lapply(all.sce, runTSNE, dimred="PCA")
set.seed(1000000)
all.sce <- lapply(all.sce, runUMAP, dimred="PCA")
```

# Clustering
```{r}
for (n in names(all.sce)) {
    g <- buildSNNGraph(all.sce[[n]], k=10, use.dimred="PCA")
    clust <- igraph::cluster_walktrap(g)$membership
    all.sce[[n]]$cluster <- factor(clust)
}
```

# Separate out the sce's
```{r}
pbmc3k <- all.sce$pbmc3k
dec3k <- all.dec$pbmc3k

pbmc4k <- all.sce$pbmc4k
dec4k <- all.dec$pbmc4k
```

## Restrict to common features
```{r}
universe <- intersect(rownames(pbmc3k), rownames(pbmc4k))
pbmc3k <- pbmc3k[universe,]
pbmc4k <- pbmc4k[universe,]

# Also subsetting the variance modelling results
dec3k <- dec3k[universe,]
dec4k <- dec4k[universe,]
```

# Rescale 
This adjust for differences in sequencing depth in batches
```{r}
rescaled <- multiBatchNorm(pbmc3k, pbmc4k)
pbmc3k <- rescaled[[1]]
pbmc4k <- rescaled[[2]]
```

## Average the variance components across batches 
```{r}
combined.dec <- combineVar(dec3k, dec4k)
chosen.hvgs <- combined.dec$bio > 0
```

# Combine the datasets into a single sce
```{r}
rowData(pbmc3k) <- rowData(pbmc4k)
pbmc3k$batch <- "3k"
pbmc4k$batch <- "4k"
sce <- cbind(pbmc3k, pbmc4k)
```

# Create a psuedobulk
Using 'label' and 'sample' as our two factors; each column of the output corresponds to one unique combination of these two factors.

```{r}
summed <- aggregateAcrossCells(sce, 
  id=DataFrame(
    label=sce$label,
    sample=sce$sample))
```

# Perform DE tests for all levels of a factor in a flattened sce
In this example the cell type is "batch".  

```{r}
de.results <- list()

for (i in unique(sce$batch)) {
  current <- summed[,i==sce$batch]
  y <- DGEList(counts(current), samples=colData(current))

  discarded <- isOutlier(
    colSums(counts(current)), log=TRUE, type="lower")
  y <- y[,!discarded]
  y <- y[filterByExpr(y, group=current$wildtype),]

  y <- calcNormFactors(y)

  # Construct the design matrix. This is going to require changing the model formula
  # The try clause is for the case when there are not enough cells for DE test to run
  design <- try(
    model.matrix(
      ~0 + factor(pool) + factor(wildtype), y$samples),
    silent=TRUE)
    if (is(design, "try-error") || 
      qr(design)$rank==nrow(design) ||
      qr(design)$rank < ncol(design)) {
        next
    }
  colnames(design) <- gsub(
    "factor|\\(|\\)|TRUE", "", colnames(design))

    y <- estimateDisp(y, design)
    fit <- glmQLFit(y, design)
    res <- glmQLFTest(fit, coef="wildtype")
    de.results[[i]] <- res
}
```


# Cleanup
```{r}
saveRDS(sce,
        here(
          "path_to_file"
        ))
sessionInfo()
```